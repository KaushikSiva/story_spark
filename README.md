# Storyboard Image API (Flask)

Backend API that creates a 5‑scene children’s storyboard and generates one illustration per scene. It can use a local OpenAI‑compatible LLM to write the story (preferred) and Google’s image generation to render each scene. Images are saved to `/static/generated` so your frontend can display them by URL.

Primary implementation: `app2.py`.

## Endpoints

- GET `/api/storyboard`
  - Query params:
    - `theme` (string, optional): Story theme. If omitted, a friendly theme is chosen.
    - `style` (string, optional): Image style. Default: `colorful, soft, friendly, picture book illustration`.
    - `seed` (int, optional): Passed to LLM when supported to encourage determinism.
    - `ttl_seconds` (int, optional): Lifetime before generated files are deleted. Minimum 10. Default 3600.
    - `require_local` (bool, optional): If `true`, fail if local LLM call fails instead of using fallback.
    - `api_style` (string, optional): Force LLM API style: `auto` (default), `chat`, or `completions`.
  - Response (JSON):
    - `count`: Number of scenes.
    - `model`: Image model used.
    - `size`: Image size reported by backend.
    - `style`: Style string applied to image prompts.
    - `ttl_seconds`: Seconds until files are deleted.
    - `story_source`: `local_gpt` if generated by local LLM, or `fallback` if the built‑in generator was used.
    - `llm_error` (optional): Error string if local LLM failed and fallback was used.
    - `scenes`: Array of 5 objects `{ index, text, image_url, filename }`.

- GET `/health2` — basic health check for this app.

## Quick Start

1. Python 3.9+ recommended.
2. Install deps:

   ```bash
   pip install -U google-genai && pip install -r requirements.txt
   ```

3. Set your Google API key (required for image generation):

   ```bash
   export GOOGLE_API_KEY="<your-key>"
   ```

4. (Optional) Run a local OpenAI‑compatible server for story text (e.g., LM Studio, llama.cpp server, vLLM) on `http://localhost:1234/v1`.

5. Run the server:

   ```bash
   python app2.py
   ```

6. Test the API:

   ```bash
   curl "http://localhost:8001/api/storyboard?theme=rainbow%20kites&style=colorful"
   ```

The response includes scene image URLs under `/static/generated/...` which you can render directly.

## Configuration

Environment variables read by `app2.py`:

- `GOOGLE_API_KEY` (required): API key for Google Generative AI.
- `GENERATION_MODEL` (optional): Image model, default `models/gemini-2.5-flash-image-preview`.
- `IMAGE_SIZE` (optional): Reported image size string, default `1024x1024`.
- `OUTPUT_DIR` (optional): Directory for images, default `static/generated`.
- `OUTPUT_TTL_SECONDS` (optional): File lifetime before deletion, default `3600`.
- `CORS_ALLOW_ORIGINS` (optional): CORS `Access-Control-Allow-Origin`, default `*`.
- `HOST` / `PORT` (optional): Bind address/port, defaults `0.0.0.0:8001` when running `app2.py` directly.

LLM (story text) configuration:

- `LLM_BASE_URL` (optional): Base URL for OpenAI‑compatible endpoint. Default `http://localhost:1234/v1`.
- `LLM_MODEL` (optional): Model name to send to the endpoint. Default `openai/gpt-oss-20b`.
- `LLM_TIMEOUT_SECONDS` (optional): HTTP timeout in seconds. Default `45`.
- `LLM_API_KEY` (optional): Bearer token for the endpoint, if needed.
- `LLM_API_STYLE` (optional): `auto` (try chat then completions), `chat`, or `completions`. Default `auto`.
- `LLM_CHAT_PATH` (optional): Chat path, default `/chat/completions`.
- `LLM_COMPLETIONS_PATH` (optional): Completions path, default `/completions`.

Behavior notes:

- If the local LLM call fails or is unavailable, the server falls back to a built‑in, gentle 5‑scene generator unless `require_local=true` is set.
- Generated files are deleted after `ttl_seconds`. Increase it if you need longer availability.

## How It Works

High level flow in `app2.py`:

- Story generation: `/api/storyboard` calls a local OpenAI‑compatible endpoint with a strict JSON system prompt and extracts a `{ "scenes": [{"text": ...}, ...] }` object. If parsing fails, it attempts to recover a scenes array from free‑form text. Otherwise falls back to a built‑in generator.
- Image generation: For each scene, the app builds a kid‑safe illustration prompt and calls `google-genai` (`Client(...).models.generate_content(...)`) to obtain an image, saving one image per scene under `static/generated`.
- Cleanup: A background thread removes generated files after `ttl_seconds`.

## Frontend Integration Tips

- Use the `image_url` fields from `scenes` directly in `<img>` tags.
- Pass `style` to tune the visual look; keep it concise for best results.
- If your frontend runs on a different origin, set `CORS_ALLOW_ORIGINS` accordingly.

## Troubleshooting

- 401/403: Ensure `GOOGLE_API_KEY` is set and allowed for image generation.
- 500 with `Image generation failed`: Check model availability/quotas and that `google-genai` is installed.
- 500 with `LLM call failed`: Verify your local OpenAI‑compatible server, `LLM_BASE_URL`, and `LLM_*` settings.
- Missing images on refresh: Files are auto‑deleted after TTL; increase `ttl_seconds`.

## Files

- `app2.py`: Storyboard API (port 8001 by default).
- `app.py`: Time‑travel image API (separate, port 8000 by default).
- `requirements.txt`: Python dependencies.
- `static/generated/`: Created at runtime for image files.

## License

No license specified by default. Add one if needed.
